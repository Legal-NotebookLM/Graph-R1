# Explanation of Files in `expr/loan_arbitration/` Directory

This directory contains all the processed data from your knowledge graph ingestion. Here's what each file is for:

---

## üìÑ **JSON Files (Key-Value Storage)**

### 1. `kv_store_full_docs.json`
**Purpose:** Stores the original, complete documents before chunking  
**Content:** 51 full documents (your case files + arbitration document)  
**Format:** `{"doc-{hash}": {"content": "full document text"}}`  
**Use Case:** Reference for complete document retrieval, deduplication check

**Example:**
```json
{
  "doc-ff3707177d9ec1ad76de81c2ba2b7d09": {
    "content": "# CASE FOLDER: ARB/2024/1001\n## Phoenix Finance Ltd. vs. Priya Sharma\n..."
  }
}
```

---

### 2. `kv_store_text_chunks.json`
**Purpose:** Stores text chunks split from documents (for processing)  
**Content:** ~1,070 chunks (documents split into smaller pieces)  
**Format:** `{"chunk-{hash}": {"content": "...", "tokens": 1200, "chunk_order_index": 0, "full_doc_id": "doc-..."}}`  
**Use Case:** 
- Entity extraction works on chunks (not full docs)
- Each chunk is ~1200 tokens
- Chunks are linked back to their source document

**Why chunks?** LLMs have token limits, so large documents are split into manageable pieces.

---

### 3. `kv_store_entities.json`
**Purpose:** Stores extracted entities (people, organizations, concepts, etc.)  
**Content:** ~12,422 entities extracted from your documents  
**Format:** `{"ent-{hash}": {"entity_name": "ENTITY NAME", "content": "description"}}`  
**Use Case:** 
- Entities are nodes in your knowledge graph
- Used for entity-based search and retrieval
- Examples: "PRIYA SHARMA", "PHOENIX FINANCE LTD", "LOAN AGREEMENT", etc.

**Example:**
```json
{
  "ent-448670eb2bad01cb00507d3ec56f3e32": {
    "entity_name": "EXPERT GEMOLOGIST CERTIFICATES",
    "content": "These certificates prove the material of the gold..."
  }
}
```

---

### 4. `kv_store_hyperedges.json`
**Purpose:** Stores hyperedges (n-ary relationships between entities)  
**Content:** ~20,102 hyperedges (relationships)  
**Format:** `{"rel-{hash}": {"hyperedge_name": "...", "content": "relationship description"}}`  
**Use Case:**
- Hyperedges represent relationships between multiple entities
- Example: "Phoenix Finance Ltd. issued Loan Recall Notice to Priya Sharma on 15th January 2024"
- These form the edges in your knowledge graph

**Example:**
```json
{
  "rel-498d0a84ab11d349e8f32f3d35adb61c": {
    "hyperedge_name": "Costs: Arbitrator's fees: ‚Çπ40,000/-...",
    "content": "<hyperedge>\"**D.** Costs: Arbitrator's fees..."
  }
}
```

---

### 5. `kv_store_llm_response_cache.json`
**Purpose:** Caches LLM responses to avoid redundant API calls  
**Content:** Currently empty (cache builds as you process)  
**Format:** `{"mode": {"{hash}": {"return": "LLM response", "original_prompt": "..."}}}`  
**Use Case:**
- Saves OpenAI API costs
- If same prompt is used again, returns cached response
- Keyed by prompt hash

**Why it's empty:** Cache builds up over time. If you restart the script, it will use cached responses for already-processed chunks.

---

### 6. `kv_store_chunks.json`
**Purpose:** Vector database metadata for chunks  
**Content:** Currently empty (may be used for vector storage metadata)  
**Use Case:** Stores vector embeddings metadata for text chunks

---

## üï∏Ô∏è **Graph File**

### 7. `graph_chunk_entity_relation.graphml`
**Purpose:** The actual knowledge graph in GraphML format  
**Content:** 74,382 lines - contains nodes (entities) and edges (relationships)  
**Format:** XML-based GraphML format (readable by NetworkX, Neo4j, etc.)  
**Use Case:**
- **This is your knowledge graph!**
- Contains all entities as nodes
- Contains all relationships as edges
- Can be loaded into NetworkX, Neo4j, or other graph tools
- Used for graph traversal queries

**Structure:**
- **Nodes:** Entities (people, companies, documents, concepts)
- **Edges:** Relationships between entities
- **Attributes:** Entity types, descriptions, weights, etc.

**You can visualize this** using tools like:
- NetworkX (Python)
- Neo4j Browser
- Gephi
- yEd Graph Editor

---

## üî¢ **NumPy Embedding Files**

### 8. `corpus.npy`
**Purpose:** Dense vector embeddings for text chunks  
**Content:** NumPy array of shape `(num_chunks, embedding_dim)`  
**Use Case:**
- Each chunk is converted to a dense vector (embedding)
- Used for semantic similarity search
- Generated by FlagEmbedding model (`BAAI/bge-large-en-v1.5`)

**How it works:** Text ‚Üí Embedding Model ‚Üí Dense Vector (e.g., 1024 dimensions)

---

### 9. `corpus_entity.npy`
**Purpose:** Dense vector embeddings for entities  
**Content:** NumPy array of entity embeddings  
**Use Case:**
- Entity-based semantic search
- Find similar entities
- Used by `index_entity.bin` for fast retrieval

---

### 10. `corpus_hyperedge.npy`
**Purpose:** Dense vector embeddings for hyperedges (relationships)  
**Content:** NumPy array of hyperedge embeddings  
**Use Case:**
- Relationship-based semantic search
- Find similar relationships/patterns
- Used by `index_hyperedge.bin` for fast retrieval

---

## üîç **FAISS Index Files (Vector Search)**

### 11. `index.bin`
**Purpose:** FAISS index for fast similarity search on text chunks  
**Content:** Binary FAISS index file  
**Use Case:**
- **Fast vector similarity search** (milliseconds instead of seconds)
- When you query "loan default", it finds similar chunks quickly
- Uses `corpus.npy` embeddings

**How it works:**
1. Query text ‚Üí Embedding ‚Üí Vector
2. FAISS searches `index.bin` for similar vectors
3. Returns top-k most similar chunks

---

### 12. `index_entity.bin`
**Purpose:** FAISS index for entity similarity search  
**Content:** Binary FAISS index for entities  
**Use Case:**
- Fast entity search
- Find entities similar to your query
- Uses `corpus_entity.npy` embeddings

**Example Query:** "Phoenix Finance" ‚Üí Finds similar entities like "Phoenix Finance Ltd", "Finance Company", etc.

---

### 13. `index_hyperedge.bin`
**Purpose:** FAISS index for hyperedge (relationship) similarity search  
**Content:** Binary FAISS index for relationships  
**Use Case:**
- Fast relationship search
- Find similar relationship patterns
- Uses `corpus_hyperedge.npy` embeddings

**Example Query:** "loan default arbitration" ‚Üí Finds similar relationships/patterns

---

## üìä **Data Flow Summary**

```
1. corpus.jsonl (Input)
   ‚Üì
2. Documents ‚Üí kv_store_full_docs.json
   ‚Üì
3. Chunking ‚Üí kv_store_text_chunks.json
   ‚Üì
4. Entity Extraction (LLM) ‚Üí kv_store_entities.json + kv_store_hyperedges.json
   ‚Üì
5. Graph Construction ‚Üí graph_chunk_entity_relation.graphml
   ‚Üì
6. Embedding Generation ‚Üí corpus.npy, corpus_entity.npy, corpus_hyperedge.npy
   ‚Üì
7. FAISS Index Creation ‚Üí index.bin, index_entity.bin, index_hyperedge.bin
```

---

## üéØ **How These Files Are Used**

### **During Query/Retrieval:**

1. **User Query:** "What is the loan default process for Priya Sharma?"

2. **Vector Search (FAISS):**
   - Query ‚Üí Embedding
   - Search `index.bin` ‚Üí Find similar chunks
   - Search `index_entity.bin` ‚Üí Find relevant entities
   - Search `index_hyperedge.bin` ‚Üí Find relevant relationships

3. **Graph Traversal:**
   - Load `graph_chunk_entity_relation.graphml`
   - Start from entity "PRIYA SHARMA"
   - Traverse edges to find related entities/relationships
   - Return subgraph

4. **Retrieval:**
   - Get full context from `kv_store_text_chunks.json`
   - Get entity details from `kv_store_entities.json`
   - Get relationship details from `kv_store_hyperedges.json`

5. **Response:** Combined information from graph + vector search

---

## üîß **File Sizes & Performance**

| File | Size | Purpose | Access Speed |
|------|------|---------|--------------|
| `kv_store_*.json` | Small-Medium | Key-value lookup | Fast (in-memory) |
| `graph_chunk_entity_relation.graphml` | Large (74K lines) | Graph structure | Medium (load once) |
| `*.npy` | Medium-Large | Embeddings | Fast (NumPy) |
| `*.bin` | Medium | FAISS indices | **Very Fast** (optimized) |

---

## üí° **Key Takeaways**

1. **JSON files** = Structured data storage (documents, chunks, entities, relationships)
2. **GraphML file** = Knowledge graph structure (nodes + edges)
3. **NumPy files** = Dense vector representations (for semantic search)
4. **FAISS files** = Fast similarity search indices (for retrieval)

**Together, they enable:**
- ‚úÖ Fast semantic search (FAISS)
- ‚úÖ Graph traversal (GraphML)
- ‚úÖ Entity/relationship retrieval (JSON)
- ‚úÖ Complete context retrieval (chunks + documents)

---

## üöÄ **Next Steps**

You can now:
1. **Query the graph** using `script_api.py` (retrieval API)
2. **Visualize the graph** using NetworkX or Neo4j
3. **Search entities** programmatically
4. **Use for training** (if you add LLM training components later)

All your knowledge is now structured and searchable! üéâ

